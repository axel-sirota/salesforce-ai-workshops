{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Session 4: Debugging LLM-Based Features - SOLUTIONS\n\n**This is the SOLUTIONS notebook with all code exercises completed.**\n\n---\n\n\n**Salesforce AI Workshop Series**\n\n---\n\n## Learning Objectives\n\nBy the end of this session, you will be able to:\n\n1. **Debug LLM reasoning chains** to understand WHY models made decisions\n2. **Distinguish system vs model failures** in 30 seconds using traces\n3. **Use Langfuse** for LLM-specific observability (generations, tool calls, reasoning)\n4. **Replay production failures** for root cause analysis\n5. **Convert failures into regression tests** that prevent recurrence\n\n## Prerequisites\n\n- Sessions 1-2 completed (DevHub with OpenTelemetry + DeepEval testing)\n- Basic understanding of LLM tool calling\n- No prior Langfuse experience required\n\n## Session Structure\n\n| Time | Activity |\n|------|----------|\n| 0:00-0:15 | Setup + The Wrong Tool Mystery |\n| 0:15-0:35 | 5-Layer LLM Failure Framework |\n| 0:35-1:05 | **Lab 1:** Add Langfuse to DevHub |\n| 1:05-1:15 | Break |\n| 1:15-1:30 | Demo: Trace Replay Workflow |\n| 1:30-2:10 | **Lab 2:** Debug 4 Failure Scenarios |\n| 2:10-2:35 | **Lab 3:** Failure → Regression Test |\n| 2:35-2:45 | Wrap-up + Take-Home |",
   "id": "cell-000"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## The Problem: \"Why Does The Agent Keep Calling The Wrong Tool?\"\n\nYour customer service agent repeatedly invokes the wrong tool...\n\n**The Bug Report:**\n> \"User asked about order STATUS, but the agent called find_owner instead of check_status!\"\n\nYou check your application logs:\n```\nINFO: query=\"What's the status of order #67890?\"\nINFO: tool_called=find_owner\nINFO: tool_args={\"service_name\": \"orders\"}\n```\n\nThat tells you WHAT happened, but not WHY.\n\n**Questions logs DON'T answer:**\n- Why did the model choose find_owner instead of check_status?\n- What was in the conversation history that influenced this?\n- What was the model's reasoning process?\n\n**Is this:**\n- A routing bug in your code?\n- A prompt problem?\n- A model error?\n- Context from a previous conversation turn?\n\n**Without LLM observability, you're debugging blind.**\n\nThis session teaches you how to see inside the LLM's reasoning process.",
   "id": "cell-001"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## What We'll Build Today\n\n| Component | Purpose |\n|-----------|---------|\n| **Langfuse Integration** | See LLM reasoning, not just actions |\n| **5-Layer Framework** | Systematic failure categorization |\n| **Debug 4 Scenarios** | Hands-on failure diagnosis with CODE |\n| **Failure → Test Pipeline** | Never have the same bug twice |\n\n### The Key Insight\n\n**Session 1 (Jaeger/OpenTelemetry):** Shows WHERE something happened\n- Service latencies, error propagation, bottlenecks\n\n**Session 4 (Langfuse):** Shows WHY the model decided\n- Tool selection reasoning, context that influenced decisions, hallucination detection\n\nBoth are essential. Today we add the \"WHY\" layer.",
   "id": "cell-002"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SETUP: Install Required Packages\n# =============================================================================\n# Langfuse v3 for LLM observability\n# DeepEval 3.x for evaluation metrics\n\n!pip install -q langfuse>=3.0.0 deepeval>=3.0.0 openai>=1.0.0 chromadb>=0.4.0 rich>=13.0.0\n\nprint(\"Packages installed!\")",
   "id": "cell-003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CONFIGURATION: API Keys and Student Identity\n# =============================================================================\nimport os\nimport uuid\n\n# ─────────────────────────────────────────────────────────────────────────────\n# LANGFUSE CREDENTIALS (Pre-configured for workshop)\n# ─────────────────────────────────────────────────────────────────────────────\nLANGFUSE_PUBLIC_KEY = \"pk-lf-22dfa276-31da-4cdb-8b3d-52e7c7005c2a\"\nLANGFUSE_SECRET_KEY = \"sk-lf-d247e9f3-eacf-4cec-87fd-d4e3b116ad32\"\nLANGFUSE_HOST = \"https://us.cloud.langfuse.com\"\n\n# OpenAI API Key\nOPENAI_API_KEY = \"sk-...\"  # Or use instructor-provided key\n\n# ─────────────────────────────────────────────────────────────────────────────\n# STUDENT: CHANGE THIS TO YOUR NAME! (lowercase, no spaces)\n# ─────────────────────────────────────────────────────────────────────────────\nSTUDENT_NAME = \"your-name-here\"  # <-- CHANGE THIS! e.g., \"sarah-chen\"\n\n# ─────────────────────────────────────────────────────────────────────────────\n# VALIDATION: Ensure student entered their name\n# ─────────────────────────────────────────────────────────────────────────────\nif STUDENT_NAME == \"your-name-here\" or not STUDENT_NAME.strip():\n    raise ValueError(\n        \"\\n\" + \"=\"*60 + \"\\n\"\n        \"ERROR: You must enter your name!\\n\"\n        \"Change STUDENT_NAME above from 'your-name-here' to your actual name.\\n\"\n        \"Example: STUDENT_NAME = \\\"sarah-chen\\\"\\n\"\n        + \"=\"*60\n    )\n\n# Set environment variables\nos.environ[\"LANGFUSE_PUBLIC_KEY\"] = LANGFUSE_PUBLIC_KEY\nos.environ[\"LANGFUSE_SECRET_KEY\"] = LANGFUSE_SECRET_KEY\nos.environ[\"LANGFUSE_HOST\"] = LANGFUSE_HOST\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\n# Generate unique session ID for this workshop run\nLAB_SESSION_ID = f\"{STUDENT_NAME}-session-{uuid.uuid4().hex[:8]}\"\n\nprint(f\"Welcome, {STUDENT_NAME}!\")\nprint(f\"Session ID: {LAB_SESSION_ID}\")\nprint(f\"Langfuse Host: {LANGFUSE_HOST}\")\nprint(\"\\nYour traces will be tagged with your name for easy filtering.\")",
   "id": "cell-004"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# VERIFY: Test Langfuse Connection\n# =============================================================================\n# Langfuse v3's get_client() is idempotent (singleton pattern).\n# Safe to re-run this cell without issues.\n\nfrom langfuse import get_client\n\ntry:\n    langfuse = get_client()\n\n    # Create a test trace\n    with langfuse.start_as_current_span(name=\"connection-test\") as span:\n        span.update(\n            input={\"test\": \"connection\"},\n            output={\"status\": \"success\"}\n        )\n\n    langfuse.flush()\n\n    print(\"Langfuse connection successful!\")\n    print(f\"View traces at: {LANGFUSE_HOST}\")\n    print(f\"Filter by session: {LAB_SESSION_ID}\")\n\nexcept Exception as e:\n    print(f\"Langfuse connection failed: {e}\")\n    print(\"Check your LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY\")",
   "id": "cell-005"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CONFIGURATION: DevHub Settings with Failure Modes\n# =============================================================================\nfrom dataclasses import dataclass\n\n@dataclass\nclass Config:\n    \"\"\"DevHub configuration with intentional failure modes for debugging practice.\"\"\"\n\n    # LLM Settings\n    LLM_MODEL: str = \"gpt-4o-mini\"\n    LLM_MAX_TOKENS: int = 1024\n    LLM_TEMPERATURE: float = 0.3\n\n    # Latency ranges (milliseconds)\n    VECTOR_DB_LATENCY_MIN: int = 50\n    VECTOR_DB_LATENCY_MAX: int = 200\n    TEAM_DB_LATENCY_MIN: int = 20\n    TEAM_DB_LATENCY_MAX: int = 100\n    STATUS_API_LATENCY_MIN: int = 30\n    STATUS_API_LATENCY_MAX: int = 150\n\n    # Session 1-2 failure rates\n    VECTOR_DB_FAILURE_RATE: float = 0.05\n    VECTOR_DB_SLOW_QUERY_RATE: float = 0.10\n    VECTOR_DB_LOW_SIMILARITY_RATE: float = 0.15\n    TEAM_DB_STALE_DATA_RATE: float = 0.10\n    STATUS_API_TIMEOUT_RATE: float = 0.02\n\n    # Session 4: LLM-specific failure scenarios (for debugging practice)\n    CONTEXT_BLEED_RATE: float = 0.20      # Previous context affects tool selection\n    HALLUCINATION_RATE: float = 0.15      # Model invents details\n    PARAM_ERROR_RATE: float = 0.10        # Wrong parameters to correct tool\n\nconfig = Config()\nprint(\"Config loaded with Session 4 failure modes\")",
   "id": "cell-006"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DATA: Load DevHub Knowledge Base\n# =============================================================================\n\n# Documentation entries\nDOCS_DATA = [\n    {\n        \"id\": \"doc-payments-auth\",\n        \"title\": \"Payments API Authentication\",\n        \"category\": \"api\",\n        \"content\": \"To authenticate with the Payments API, use OAuth 2.0 client credentials flow. Obtain your client_id and client_secret from the Developer Portal. Make a POST request to /oauth/token with grant_type=client_credentials. The response includes an access_token valid for 1 hour. Include this token in the Authorization header as 'Bearer {token}' for all subsequent API calls.\"\n    },\n    {\n        \"id\": \"doc-billing-service\",\n        \"title\": \"Billing Service Overview\",\n        \"category\": \"service\",\n        \"content\": \"The Billing Service handles all subscription management, invoice generation, and payment processing. Key endpoints: POST /v1/subscriptions (create), GET /v1/invoices (list), POST /v1/refunds (process refund). Rate limit: 100 requests/minute. Contact #payments-support for billing issues.\"\n    },\n    {\n        \"id\": \"doc-error-handling\",\n        \"title\": \"Error Handling Standards\",\n        \"category\": \"standards\",\n        \"content\": \"All APIs return standard error responses with error_code, message, and request_id fields. Common codes: 400 (bad request), 401 (unauthorized), 429 (rate limited), 500 (internal error). Always log the request_id for debugging. Implement exponential backoff for 429 and 5xx errors.\"\n    },\n    {\n        \"id\": \"doc-rate-limiting\",\n        \"title\": \"Rate Limiting Configuration\",\n        \"category\": \"guide\",\n        \"content\": \"Default rate limits: 100 req/min for standard tier, 1000 req/min for premium. Limits are per API key. Response header X-RateLimit-Remaining shows remaining quota. When rate limited, wait for X-RateLimit-Reset seconds before retrying.\"\n    }\n]\n\n# Teams and owners\nTEAMS_DATA = {\n    \"teams\": [\n        {\"id\": \"team-payments\", \"name\": \"Payments Team\", \"slack_channel\": \"#payments-support\"},\n        {\"id\": \"team-platform\", \"name\": \"Platform Team\", \"slack_channel\": \"#platform-help\"},\n        {\"id\": \"team-data\", \"name\": \"Data Platform\", \"slack_channel\": \"#data-platform\"}\n    ],\n    \"owners\": [\n        {\"id\": \"owner-sarah\", \"name\": \"Sarah Chen\", \"email\": \"sarah.chen@company.com\",\n         \"team_id\": \"team-payments\", \"services\": [\"payments-api\", \"billing-service\", \"billing\"], \"is_active\": True},\n        {\"id\": \"owner-james\", \"name\": \"James Wilson\", \"email\": \"james.wilson@company.com\",\n         \"team_id\": \"team-platform\", \"services\": [\"rate-limiting\", \"api-gateway\"], \"is_active\": True},\n        {\"id\": \"owner-david\", \"name\": \"David Kim\", \"email\": \"david.kim@company.com\",\n         \"team_id\": \"team-data\", \"services\": [\"vector-search\", \"embeddings\"], \"is_active\": False}  # Left company\n    ]\n}\n\n# Service status\nSTATUS_DATA = {\n    \"services\": [\n        {\"name\": \"payments-api\", \"status\": \"healthy\", \"uptime_percent\": 99.95},\n        {\"name\": \"auth-service\", \"status\": \"healthy\", \"uptime_percent\": 99.99},\n        {\"name\": \"staging\", \"status\": \"degraded\", \"uptime_percent\": 95.5,\n         \"last_incident\": \"2024-01-15T09:00:00Z\",\n         \"incident_description\": \"Database connection pool exhaustion causing intermittent 503 errors\"},\n        {\"name\": \"vector-search\", \"status\": \"healthy\", \"uptime_percent\": 99.8},\n        {\"name\": \"api-gateway\", \"status\": \"healthy\", \"uptime_percent\": 99.97}\n    ]\n}\n\nprint(f\"Loaded: {len(DOCS_DATA)} docs, {len(TEAMS_DATA['owners'])} owners, {len(STATUS_DATA['services'])} services\")",
   "id": "cell-007"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SERVICES: DevHub Components (Simplified for Session 4)\n# =============================================================================\nimport time\nimport random\n\nclass VectorDB:\n    \"\"\"Simplified vector search for workshop.\"\"\"\n\n    def __init__(self, docs: list):\n        self.docs = {d[\"id\"]: d for d in docs}\n\n    def search(self, query: str, top_k: int = 3) -> dict:\n        \"\"\"Simple keyword-based search.\"\"\"\n        query_lower = query.lower()\n        results = []\n\n        for doc in self.docs.values():\n            score = 0\n            content_lower = doc[\"content\"].lower()\n            title_lower = doc[\"title\"].lower()\n\n            for word in query_lower.split():\n                if word in content_lower:\n                    score += 1\n                if word in title_lower:\n                    score += 2\n\n            if score > 0:\n                results.append({\"doc\": doc, \"score\": score})\n\n        results.sort(key=lambda x: x[\"score\"], reverse=True)\n        top_results = results[:top_k]\n\n        return {\n            \"documents\": [r[\"doc\"][\"content\"] for r in top_results],\n            \"metadatas\": [{\"title\": r[\"doc\"][\"title\"], \"id\": r[\"doc\"][\"id\"]} for r in top_results],\n            \"distances\": [1.0 / (r[\"score\"] + 1) for r in top_results]\n        }\n\n\nclass TeamDB:\n    \"\"\"Team and owner lookup.\"\"\"\n\n    def __init__(self, data: dict):\n        self.teams = {t[\"id\"]: t for t in data[\"teams\"]}\n        self.owners = data[\"owners\"]\n\n    def find_owner(self, service_or_topic: str) -> dict:\n        \"\"\"Find owner for a service.\"\"\"\n        service_lower = service_or_topic.lower()\n\n        for owner in self.owners:\n            for service in owner[\"services\"]:\n                if service_lower in service.lower() or service.lower() in service_lower:\n                    team = self.teams.get(owner[\"team_id\"], {})\n                    return {\n                        \"found\": True,\n                        \"owner_name\": owner[\"name\"],\n                        \"owner_email\": owner[\"email\"],\n                        \"team_name\": team.get(\"name\", \"Unknown\"),\n                        \"slack_channel\": team.get(\"slack_channel\", \"\"),\n                        \"is_active\": owner[\"is_active\"]\n                    }\n\n        return {\"found\": False}\n\n\nclass StatusAPI:\n    \"\"\"Service status checker.\"\"\"\n\n    def __init__(self, data: dict):\n        self.services = {s[\"name\"]: s for s in data[\"services\"]}\n\n    def check_status(self, service_name: str) -> dict:\n        \"\"\"Check service status.\"\"\"\n        service_lower = service_name.lower()\n\n        for name, service in self.services.items():\n            if service_lower in name.lower() or name.lower() in service_lower:\n                result = {\n                    \"found\": True,\n                    \"service_name\": name,\n                    \"status\": service[\"status\"],\n                    \"uptime_percent\": service[\"uptime_percent\"]\n                }\n                if \"incident_description\" in service:\n                    result[\"incident\"] = service[\"incident_description\"]\n                return result\n\n        return {\"found\": False, \"service_name\": service_name}\n\n\n# Initialize services\nvector_db = VectorDB(DOCS_DATA)\nteam_db = TeamDB(TEAMS_DATA)\nstatus_api = StatusAPI(STATUS_DATA)\n\nprint(\"Services initialized: VectorDB, TeamDB, StatusAPI\")",
   "id": "cell-008"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DEVHUB V4: Multi-turn Conversation Support (NO TRACING YET)\n# =============================================================================\n# This version supports conversation history, which enables the \"context bleed\"\n# bug we'll debug in Lab 2.\n\nfrom openai import OpenAI\nimport json\n\nclass DevHubV4:\n    \"\"\"DevHub with multi-turn conversation support but NO tracing.\"\"\"\n\n    def __init__(self, vector_db: VectorDB, team_db: TeamDB, status_api: StatusAPI):\n        self.vector_db = vector_db\n        self.team_db = team_db\n        self.status_api = status_api\n        self.client = OpenAI()\n        self.sessions: dict[str, list] = {}  # session_id -> list of turns\n\n        # Tool definitions for OpenAI function calling\n        self.tools = [\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"search_docs\",\n                    \"description\": \"Search documentation for API guides, SDK docs, how-to guides\",\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"query\": {\"type\": \"string\", \"description\": \"Search query\"}\n                        },\n                        \"required\": [\"query\"]\n                    }\n                }\n            },\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"find_owner\",\n                    \"description\": \"Find the person or team who owns a service. Use for cancellation requests, escalations, or 'who can help' questions.\",\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"service_name\": {\"type\": \"string\", \"description\": \"Service to find owner for\"}\n                        },\n                        \"required\": [\"service_name\"]\n                    }\n                }\n            },\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"check_status\",\n                    \"description\": \"Check if a service is healthy, degraded, or down\",\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"service_name\": {\"type\": \"string\", \"description\": \"Service to check\"}\n                        },\n                        \"required\": [\"service_name\"]\n                    }\n                }\n            }\n        ]\n\n    def _get_system_prompt(self) -> str:\n        return \"\"\"You are DevHub, an AI assistant for developers.\nYou help with:\n- Finding documentation (use search_docs)\n- Finding service owners (use find_owner) - especially for cancellations or escalations\n- Checking service health (use check_status)\n\nBe concise and helpful. Use the appropriate tool for each question.\"\"\"\n\n    def _build_messages(self, user_query: str, session_id: str = None) -> list:\n        \"\"\"Build messages with conversation history if session exists.\"\"\"\n        messages = []\n\n        # Include history if session exists (last 3 turns)\n        if session_id and session_id in self.sessions:\n            for turn in self.sessions[session_id][-3:]:\n                messages.append({\"role\": \"user\", \"content\": turn[\"user\"]})\n                messages.append({\"role\": \"assistant\", \"content\": turn[\"assistant\"]})\n\n        messages.append({\"role\": \"user\", \"content\": user_query})\n        return messages\n\n    def _execute_tool(self, tool_name: str, args: dict) -> dict:\n        \"\"\"Execute a tool and return results.\"\"\"\n        try:\n            if tool_name == \"search_docs\":\n                result = self.vector_db.search(args.get(\"query\", \"\"))\n                return {\"success\": True, \"data\": result}\n            elif tool_name == \"find_owner\":\n                result = self.team_db.find_owner(args.get(\"service_name\", \"\"))\n                return {\"success\": True, \"data\": result}\n            elif tool_name == \"check_status\":\n                result = self.status_api.check_status(args.get(\"service_name\", \"\"))\n                return {\"success\": True, \"data\": result}\n            else:\n                return {\"success\": False, \"error\": f\"Unknown tool: {tool_name}\"}\n        except Exception as e:\n            return {\"success\": False, \"error\": str(e)}\n\n    def query(self, user_query: str, session_id: str = None) -> dict:\n        \"\"\"Process a query with optional session context.\"\"\"\n        messages = self._build_messages(user_query, session_id)\n\n        # Get tool selection from LLM\n        response = self.client.chat.completions.create(\n            model=config.LLM_MODEL,\n            messages=[{\"role\": \"system\", \"content\": self._get_system_prompt()}] + messages,\n            tools=self.tools,\n            tool_choice=\"auto\",\n            max_tokens=config.LLM_MAX_TOKENS,\n            temperature=config.LLM_TEMPERATURE\n        )\n\n        assistant_message = response.choices[0].message\n        tools_called = []\n        tool_results = []\n\n        # Execute tools if any\n        if assistant_message.tool_calls:\n            for tool_call in assistant_message.tool_calls:\n                tool_name = tool_call.function.name\n                tool_args = json.loads(tool_call.function.arguments)\n\n                result = self._execute_tool(tool_name, tool_args)\n\n                tools_called.append(tool_name)\n                tool_results.append({\n                    \"tool\": tool_name,\n                    \"args\": tool_args,\n                    \"result\": result\n                })\n\n            # Generate final response with tool results\n            tool_messages = messages + [assistant_message.model_dump()]\n            for i, tool_call in enumerate(assistant_message.tool_calls):\n                tool_messages.append({\n                    \"role\": \"tool\",\n                    \"tool_call_id\": tool_call.id,\n                    \"content\": json.dumps(tool_results[i][\"result\"])\n                })\n\n            final_response = self.client.chat.completions.create(\n                model=config.LLM_MODEL,\n                messages=[{\"role\": \"system\", \"content\": self._get_system_prompt()}] + tool_messages,\n                max_tokens=config.LLM_MAX_TOKENS\n            )\n\n            response_text = final_response.choices[0].message.content\n        else:\n            response_text = assistant_message.content or \"I couldn't process that request.\"\n\n        # Store in session\n        if session_id:\n            if session_id not in self.sessions:\n                self.sessions[session_id] = []\n            self.sessions[session_id].append({\n                \"user\": user_query,\n                \"assistant\": response_text,\n                \"tools\": tools_called\n            })\n\n        return {\n            \"response\": response_text,\n            \"tools_called\": tools_called,\n            \"tool_results\": tool_results\n        }\n\n\n# Create DevHub instance\ndevhub = DevHubV4(vector_db, team_db, status_api)\nprint(\"DevHub V4 created (multi-turn support, no tracing)\")",
   "id": "cell-009"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TEST: Verify DevHub V4 Works\n# =============================================================================\n\ntest_result = devhub.query(\"How do I authenticate with the Payments API?\")\nprint(f\"Response: {test_result['response'][:200]}...\")\nprint(f\"Tools called: {test_result['tools_called']}\")\nprint(\"\\nDevHub V4 is working!\")",
   "id": "cell-010"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Setup Complete!\n\nIf you see:\n- Packages installed\n- Langfuse connection successful\n- DevHub V4 created and working\n\n**You're ready to begin!**\n\n---\n\n**Next:** We'll explore a mysterious bug - the \"Wrong Tool Mystery\" - and see why traditional debugging fails for LLM applications.",
   "id": "cell-011"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Topic 1: The Wrong Tool Mystery\n\n## A Real Production Bug That Changes Everything\n\nIn traditional software, bugs are deterministic. Run the same code twice, get the same result. You can set breakpoints, inspect variables, trace execution paths.\n\n**LLM-based features break all of this.**\n\nThe bug we're about to explore actually happened in production. An AI assistant started answering questions incorrectly—but only sometimes, and only for certain users, and only after they'd asked a few questions.\n\nThe traditional debugging approach failed completely:\n- **Logs showed the request arrived** ✓\n- **Logs showed the response was sent** ✓\n- **Everything in between?** A black box.\n\nThis is the **observability gap** that makes LLM features so difficult to debug. Today, we'll close that gap.",
   "id": "cell-012"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## The Bug: Wrong Tool Called\n\n![Wrong Tool Mystery](https://raw.githubusercontent.com/axel-sirota/salesforce-ai-workshops/main/exercises/session_04/charts/00_wrong_tool_mystery.svg)\n\n**What happened:**\n\n| Turn | User Query | Expected Tool | Actual Tool |\n|------|-----------|---------------|-------------|\n| 1 | \"I need to cancel my order #12345\" | find_owner | find_owner |\n| 2 | \"What's the status of order #67890?\" | check_status | find_owner |\n\n**Turn 1:** User asks about cancellation → Agent correctly calls `find_owner` to escalate\n\n**Turn 2:** User asks about order status → Agent INCORRECTLY calls `find_owner` instead of `check_status`\n\n**The question:** Why did the agent pick the wrong tool for Turn 2?",
   "id": "cell-013"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DEMO: Recreate the \"Wrong Tool\" Bug\n# =============================================================================\n# We'll loop until the bug is reproduced (it doesn't happen 100% of the time)\n\nimport time\n\nmax_attempts = 10\nbug_reproduced = False\n\nfor attempt in range(1, max_attempts + 1):\n    print(f\"\\n{'='*60}\")\n    print(f\"ATTEMPT {attempt}/{max_attempts}\")\n    print('='*60)\n    \n    # Fresh session each attempt\n    bug_session = f\"bug-demo-{attempt}\"\n    \n    # TURN 1: Cancellation context\n    print(\"\\nTURN 1: Cancellation Request\")\n    turn1 = devhub.query(\n        \"I need to cancel my order #12345. Who can help?\",\n        session_id=bug_session\n    )\n    print(f\"  Query: 'I need to cancel my order #12345. Who can help?'\")\n    print(f\"  Tools called: {turn1['tools_called']}\")\n    \n    # TURN 2: Status query (should use check_status)\n    print(\"\\nTURN 2: Status Request\")\n    turn2 = devhub.query(\n        \"What's the status of order #67890?\",\n        session_id=bug_session\n    )\n    print(f\"  Query: 'What's the status of order #67890?'\")\n    print(f\"  Tools called: {turn2['tools_called']}\")\n    print(f\"  Expected: check_status\")\n    \n    # Check if bug reproduced\n    if \"find_owner\" in turn2['tools_called']:\n        print(\"\\n\" + \"!\"*60)\n        print(\"BUG REPRODUCED!\")\n        print(\"Agent called find_owner for a STATUS question!\")\n        print(\"The 'cancel' context from Turn 1 influenced Turn 2.\")\n        print(\"!\"*60)\n        bug_reproduced = True\n        break\n    else:\n        print(\"  Result: Worked correctly this time, trying again...\")\n    \n    time.sleep(0.5)\n\nif not bug_reproduced:\n    print(f\"\\nBug not reproduced in {max_attempts} attempts.\")\n    print(\"The model is being unusually consistent today!\")\n    print(\"But the bug DOES exist - we'll see it in Langfuse traces.\")",
   "id": "cell-014"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TRADITIONAL DEBUGGING: What We Know\n# =============================================================================\n# Let's see what traditional debugging tells us...\n\nprint(\"What traditional logs would show:\")\nprint(\"-\" * 40)\nprint(f\"Turn 1: query='cancel order #12345', tool=find_owner\")\nprint(f\"Turn 2: query='status of #67890', tool={turn2['tools_called']}\")\nprint()\nprint(\"What traditional logs DON'T show:\")\nprint(\"-\" * 40)\nprint(\"- What was in the conversation history?\")\nprint(\"- What context influenced the model's decision?\")\nprint(\"- Why did the model think find_owner was appropriate?\")\nprint(\"- What was the model's reasoning process?\")\nprint()\nprint(\"We see WHAT happened, but not WHY.\")",
   "id": "cell-015"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## The Visibility Gap\n\nTraditional application logging shows:\n- **Request received** ✅\n- **Tool called** ✅\n- **Response sent** ✅\n\nBut for LLM applications, we also need to see:\n- **Conversation history** that influenced the decision\n- **Model's reasoning** about which tool to use\n- **Context** passed to the model\n- **Confidence** in the tool selection\n\n**The problem:** LLMs make decisions based on context you can't see in traditional logs.\n\n**The solution:** LLM-specific observability tools like **Langfuse**.",
   "id": "cell-016"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Spoiler: Why This Bug Happens\n\n**Root Cause: Context Bleed**\n\nWhen we built DevHub V4 with multi-turn support, we included conversation history:\n\n```python\ndef _build_messages(self, user_query: str, session_id: str = None) -> list:\n    messages = []\n    if session_id and session_id in self.sessions:\n        for turn in self.sessions[session_id][-3:]:  # Last 3 turns\n            messages.append({\"role\": \"user\", \"content\": turn[\"user\"]})\n            messages.append({\"role\": \"assistant\", \"content\": turn[\"assistant\"]})\n    messages.append({\"role\": \"user\", \"content\": user_query})\n    return messages\n```\n\n**What happens:**\n1. Turn 1 mentions \"cancel\" → Agent correctly calls `find_owner`\n2. Turn 2's context INCLUDES Turn 1 (with \"cancel\")\n3. Model sees \"cancel\" in history and thinks \"cancellation context\"\n4. Model chooses `find_owner` because \"cancel\" keywords are still present\n\n**Without Langfuse:** You'd spend HOURS guessing\n**With Langfuse:** You'd see the history in 30 SECONDS\n\nThis is the power of LLM observability.",
   "id": "cell-017"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Insight: LLM Bugs Are Different\n\n**Traditional bugs:** Code does the wrong thing\n- Fix: Change the code\n\n**LLM bugs:** Model reasons incorrectly based on context\n- Fix: Change the context, prompt, or model settings\n\n**You need different debugging tools for different bug types.**\n\n| Bug Type | Traditional Debugging | LLM Debugging |\n|----------|----------------------|---------------|\n| Code error | Stack trace | Stack trace |\n| Performance | Profiler | Profiler |\n| **Wrong decision** | ❌ Useless | ✅ Trace reasoning |\n| **Hallucination** | ❌ Can't detect | ✅ Compare to sources |\n| **Context bleed** | ❌ Can't see context | ✅ See full history |\n\n**Coming up:** The 5-Layer Framework for systematically categorizing LLM failures.",
   "id": "cell-018"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Topic 2: The 5-Layer LLM Failure Framework\n\n## From Chaos to System: Debugging LLM Failures Methodically\n\nWhen an LLM feature fails, the natural reaction is: *\"The AI is being weird.\"*\n\nThat's not a diagnosis—it's giving up.\n\nEvery LLM failure has a root cause, and those causes fall into predictable patterns. After debugging hundreds of production LLM issues, a clear taxonomy emerges:\n\n**The 5 Layers where things go wrong:**\n1. **Prompt Layer** — What instructions did the LLM receive?\n2. **Retrieval Layer** — What context was fetched?\n3. **Generation Layer** — What did the LLM produce?\n4. **Validation Layer** — Was the output validated?\n5. **Latency Layer** — Did timing cause issues?\n\nThe framework transforms \"the AI is broken\" into \"the retrieval returned irrelevant documents\" or \"the prompt didn't include conversation history.\"\n\nOnce you know the layer, you know where to look.",
   "id": "cell-019"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## The 5-Layer Framework\n\n![5-Layer Framework](https://raw.githubusercontent.com/axel-sirota/salesforce-ai-workshops/main/exercises/session_04/charts/01_five_layer_framework.svg)\n\nWhen an LLM application fails, the problem exists in one of five layers:\n\n| Layer | Name | What Can Go Wrong |\n|-------|------|-------------------|\n| 1 | **Prompt** | Bad instructions, wrong context, history issues |\n| 2 | **Retrieval** | No relevant docs, wrong docs, stale data |\n| 3 | **Generation** | Hallucination, wrong format, refusal |\n| 4 | **Validation** | Schema errors, constraint violations |\n| 5 | **Latency** | Slow retrieval, slow LLM, timeouts |\n\n**Key insight:** Each layer has different symptoms and different fixes.",
   "id": "cell-020"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Layer 1: Prompt Layer\n\n**What it is:** The instructions and context given to the model.\n\n**What can go wrong:**\n\n| Symptom | Cause | Debug Approach |\n|---------|-------|----------------|\n| Wrong tool selected | Ambiguous tool descriptions | Check tool descriptions in trace |\n| Inconsistent behavior | Temperature too high | Check model settings |\n| Context bleed | History included bad context | Check conversation history in trace |\n| Ignores instructions | Prompt too long/confusing | Check full prompt content |\n\n**Debugging in Langfuse:**\n- View the full prompt sent to the model\n- See conversation history included\n- Check system prompt content\n- Verify tool descriptions",
   "id": "cell-021"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Layer 2: Retrieval Layer\n\n**What it is:** Finding relevant information (RAG, database queries).\n\n**What can go wrong:**\n\n| Symptom | Cause | Debug Approach |\n|---------|-------|----------------|\n| \"I don't have information about X\" | No docs match query | Check retrieval results |\n| Wrong answer | Retrieved wrong docs | Check similarity scores |\n| Outdated information | Stale data in vector DB | Check document timestamps |\n| Partial answer | Not enough docs retrieved | Check top_k setting |\n\n**Debugging in Langfuse:**\n- See what was retrieved\n- Check similarity/distance scores\n- Verify document content\n- Compare query vs retrieved docs",
   "id": "cell-022"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Layer 3: Generation Layer\n\n**What it is:** The LLM generating text/decisions.\n\n**What can go wrong:**\n\n| Symptom | Cause | Debug Approach |\n|---------|-------|----------------|\n| Hallucination | Model invents facts | Compare output to retrieval context |\n| Wrong format | Unclear format instructions | Check prompt format requirements |\n| Refusal | Safety filters triggered | Check model response |\n| Inconsistent | Non-deterministic (temperature) | Check temperature setting |\n\n**Debugging in Langfuse:**\n- Compare generation to retrieval context\n- Check if output matches instructions\n- View raw model response\n- Verify token counts and settings\n\n**This is where DeepEval helps:** FaithfulnessMetric catches hallucinations.",
   "id": "cell-023"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Layer 4: Validation Layer\n\n**What it is:** Ensuring outputs meet requirements.\n\n**What can go wrong:**\n\n| Symptom | Cause | Debug Approach |\n|---------|-------|----------------|\n| Schema errors | Model output doesn't match schema | Check JSON structure |\n| Invalid parameters | Wrong args to tool | Check tool call arguments |\n| Constraint violation | Output exceeds limits | Check constraints in trace |\n| Type errors | Wrong data types | Check parameter types |\n\n**Debugging in Langfuse:**\n- View tool call arguments\n- Check parameter values\n- Verify schema compliance\n- Compare expected vs actual format",
   "id": "cell-024"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Layer 5: Latency Layer\n\n**What it is:** Performance and timing issues.\n\n**What can go wrong:**\n\n| Symptom | Cause | Debug Approach |\n|---------|-------|----------------|\n| Slow responses | Large context window | Check token counts |\n| Timeouts | Model overloaded | Check LLM latency |\n| Bottlenecks | Slow retrieval | Check span timings |\n| Cost spikes | Too many tokens | Check token usage |\n\n**Debugging in Langfuse:**\n- View span timings\n- Check token counts\n- Identify bottleneck operations\n- Compare across traces",
   "id": "cell-025"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Debug Decision Tree: 30-Second Triage\n\n![Debug Decision Tree](https://raw.githubusercontent.com/axel-sirota/salesforce-ai-workshops/main/exercises/session_04/charts/03_debug_decision_tree.svg)\n\n**Quick triage process:**\n\n1. **Did it error?** → Check error message and stack trace\n2. **Did it pick the right tool?** → Check Prompt Layer (conversation history)\n3. **Did it pass valid parameters?** → Check Validation Layer\n4. **Did retrieval return good results?** → Check Retrieval Layer (similarity scores)\n5. **Does output match retrieval?** → Check Generation Layer (hallucination)\n6. **Is it slow?** → Check Latency Layer (span timings)\n\n**With Langfuse, you can answer these in 30 seconds instead of hours.**",
   "id": "cell-026"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Framework Summary\n\n**Use the 5-Layer Framework to:**\n\n1. **Categorize** the failure type immediately\n2. **Focus** your investigation on the right layer\n3. **Apply** layer-specific debugging techniques\n4. **Fix** the root cause, not symptoms\n\n| If you see... | Check this layer |\n|---------------|------------------|\n| Wrong tool called | Prompt (history, tool descriptions) |\n| \"No information found\" | Retrieval (query, similarity) |\n| Made-up facts | Generation (hallucination) |\n| Invalid arguments | Validation (schema, params) |\n| Slow response | Latency (timings) |\n\n**Coming up:** Lab 1 - We'll add Langfuse to DevHub so you can actually SEE these layers.",
   "id": "cell-027"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Lab 1: Add Langfuse Instrumentation to DevHub\n\n## Opening the Black Box\n\n**Duration:** ~30 minutes\n\nRemember the bug from Topic 1? We couldn't debug it because we had no visibility into what the LLM was *thinking*.\n\nLangfuse is an open-source LLM observability platform that captures every decision the model makes. Think of it as \"Chrome DevTools for LLM applications.\"\n\n**After this lab, you'll see:**\n- Exactly which tools the LLM considered and why\n- The full prompt sent to the model (with history!)\n- Token counts and latencies for each step\n- Which documents were retrieved\n- The reasoning chain that led to the response\n\n**What you'll build:**\n\n| Task | What You'll Add | Why It Matters |\n|------|-----------------|----------------|\n| 1 | Langfuse client config | Connects to observability backend |\n| 2 | `@observe()` decorator | Automatic tracing with zero code changes |\n| 3 | Tool planning spans | See which tools the LLM chooses |\n| 4 | Tool execution spans | See what each tool returns |\n| 5 | Response synthesis span | See how final answer is generated |\n\nBy the end, every query to DevHub will generate a complete trace you can replay and debug.",
   "id": "cell-028"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Langfuse Trace Model\n\n![Langfuse Trace Model](https://raw.githubusercontent.com/axel-sirota/salesforce-ai-workshops/main/exercises/session_04/charts/02_langfuse_trace_model.svg)\n\n**Hierarchy:**\n```\nSession (groups related traces)\n└── Trace (one user interaction)\n    ├── Span: tool-planning\n    │   └── Generation: LLM call\n    ├── Span: tool.search_docs\n    ├── Span: tool.find_owner\n    └── Span: response-synthesis\n        └── Generation: LLM call\n```\n\n**Key concepts:**\n- **Session:** Groups traces from same conversation\n- **Trace:** One request/response cycle\n- **Span:** A logical operation within a trace\n- **Generation:** An LLM call (automatically tracked)",
   "id": "cell-029"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Task 1: Understand Langfuse v3 Patterns\n\n**Goal:** Learn the Langfuse v3 API patterns we'll use.\n\n**Key patterns:**\n\n```python\n# Import\nfrom langfuse import observe, get_client\n\n# Get client (singleton, safe to call multiple times)\nlangfuse = get_client()\n\n# Update trace metadata\nlangfuse.update_current_trace(\n    session_id=\"...\",\n    user_id=\"...\",\n    input=\"...\",\n    metadata={...}\n)\n\n# Create nested spans\nwith langfuse.start_as_current_span(name=\"operation\", input={...}) as span:\n    # ... your code ...\n    span.update(output={...})\n```\n\n**Time:** Review only (~2 minutes)",
   "id": "cell-030"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Task 2: Create DevHubWithLangfuse Class\n\n**Goal:** Create an instrumented version of DevHub with Langfuse tracing.\n\n**What to implement:**\n\n1. **@observe() decorator** on the `query()` method\n2. **update_current_trace()** to set session and user metadata\n3. **Nested spans** for:\n   - `tool-planning`: The LLM call that selects tools\n   - `tool.{name}`: Each tool execution\n   - `response-synthesis`: The final LLM response\n\n**Pattern:**\n```python\n@observe()\ndef query(self, user_query: str, session_id: str = None) -> dict:\n    langfuse = get_client()\n    langfuse.update_current_trace(session_id=..., user_id=..., input=...)\n\n    with langfuse.start_as_current_span(name=\"tool-planning\", input={...}) as span:\n        # LLM call to select tools\n        span.update(output={...})\n\n    for tool in tools_to_call:\n        with langfuse.start_as_current_span(name=f\"tool.{tool_name}\", input=...) as span:\n            # Execute tool\n            span.update(output=...)\n\n    with langfuse.start_as_current_span(name=\"response-synthesis\", input={...}) as span:\n        # Final LLM response\n        span.update(output=...)\n```\n\n**Time:** ~15 minutes",
   "id": "cell-031"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TASK 2: Create DevHubWithLangfuse\n# =============================================================================\n# Add Langfuse instrumentation to see LLM reasoning.\n#\n# TIME: ~15 minutes\n# =============================================================================\n\nfrom langfuse import observe, get_client\nfrom openai import OpenAI\nimport json\n\nclass DevHubWithLangfuse:\n    \"\"\"\n    DevHub with Langfuse observability.\n\n    This version captures:\n    - Full query traces with session grouping\n    - Tool selection and reasoning\n    - Tool execution results\n    \"\"\"\n\n    def __init__(self, vector_db: VectorDB, team_db: TeamDB, status_api: StatusAPI):\n        self.vector_db = vector_db\n        self.team_db = team_db\n        self.status_api = status_api\n        self.client = OpenAI()\n        self.sessions: dict[str, list] = {}\n\n        # Same tools as DevHubV4\n        self.tools = [\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"search_docs\",\n                    \"description\": \"Search documentation for API guides, SDK docs, how-to guides\",\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"query\": {\"type\": \"string\", \"description\": \"Search query\"}\n                        },\n                        \"required\": [\"query\"]\n                    }\n                }\n            },\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"find_owner\",\n                    \"description\": \"Find the person or team who owns a service. Use for cancellation requests, escalations, or 'who can help' questions.\",\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"service_name\": {\"type\": \"string\", \"description\": \"Service to find owner for\"}\n                        },\n                        \"required\": [\"service_name\"]\n                    }\n                }\n            },\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"check_status\",\n                    \"description\": \"Check if a service is healthy, degraded, or down\",\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"service_name\": {\"type\": \"string\", \"description\": \"Service to check\"}\n                        },\n                        \"required\": [\"service_name\"]\n                    }\n                }\n            }\n        ]\n\n    def _get_system_prompt(self) -> str:\n        return \"\"\"You are DevHub, an AI assistant for developers.\nYou help with:\n- Finding documentation (use search_docs)\n- Finding service owners (use find_owner) - especially for cancellations or escalations\n- Checking service health (use check_status)\n\nBe concise and helpful. Use the appropriate tool for each question.\"\"\"\n\n    def _build_messages(self, user_query: str, session_id: str = None) -> list:\n        \"\"\"Build messages with conversation history.\"\"\"\n        messages = []\n\n        if session_id and session_id in self.sessions:\n            for turn in self.sessions[session_id][-3:]:\n                messages.append({\"role\": \"user\", \"content\": turn[\"user\"]})\n                messages.append({\"role\": \"assistant\", \"content\": turn[\"assistant\"]})\n\n        messages.append({\"role\": \"user\", \"content\": user_query})\n        return messages\n\n    # =========================================================================\n    # YOUR CODE: Add @observe() decorator here\n    # =========================================================================\n    def query(self, user_query: str, session_id: str = None) -> dict:\n        \"\"\"\n        Process a user query with Langfuse tracing.\n        \"\"\"\n        # ─────────────────────────────────────────────────────────────────────\n        # YOUR CODE: Get langfuse client and update trace metadata\n        # ─────────────────────────────────────────────────────────────────────\n        # langfuse = get_client()\n        # langfuse.update_current_trace(\n        #     session_id=session_id or LAB_SESSION_ID,\n        #     user_id=STUDENT_NAME,\n        #     input=user_query,\n        #     metadata={\"devhub_version\": \"v4-langfuse\"}\n        # )\n        pass  # YOUR CODE HERE\n        # ─────────────────────────────────────────────────────────────────────\n\n        # Build messages with history\n        messages = self._build_messages(user_query, session_id)\n\n        # ─────────────────────────────────────────────────────────────────────\n        # YOUR CODE: Wrap LLM call in tool-planning span\n        # ─────────────────────────────────────────────────────────────────────\n        # with langfuse.start_as_current_span(\n        #     name=\"tool-planning\",\n        #     input={\"query\": user_query, \"history_length\": len(messages) - 1}\n        # ) as planning_span:\n        #     response = self.client.chat.completions.create(...)\n        #     planning_span.update(output={...})\n\n        # For now, just make the call without span (you'll fix this)\n        response = self.client.chat.completions.create(\n            model=config.LLM_MODEL,\n            messages=[{\"role\": \"system\", \"content\": self._get_system_prompt()}] + messages,\n            tools=self.tools,\n            tool_choice=\"auto\",\n            max_tokens=config.LLM_MAX_TOKENS,\n            temperature=config.LLM_TEMPERATURE\n        )\n        # ─────────────────────────────────────────────────────────────────────\n\n        assistant_message = response.choices[0].message\n        tools_called = []\n        tool_results = []\n\n        if assistant_message.tool_calls:\n            for tool_call in assistant_message.tool_calls:\n                tool_name = tool_call.function.name\n                tool_args = json.loads(tool_call.function.arguments)\n\n                # ─────────────────────────────────────────────────────────────\n                # YOUR CODE: Wrap tool execution in a span\n                # ─────────────────────────────────────────────────────────────\n                # with langfuse.start_as_current_span(\n                #     name=f\"tool.{tool_name}\",\n                #     input=tool_args\n                # ) as tool_span:\n                #     result = self._execute_tool(tool_name, tool_args)\n                #     tool_span.update(output=result)\n\n                # For now, just execute without span (you'll fix this)\n                result = self._execute_tool(tool_name, tool_args)\n                # ─────────────────────────────────────────────────────────────\n\n                tools_called.append(tool_name)\n                tool_results.append({\n                    \"tool\": tool_name,\n                    \"args\": tool_args,\n                    \"result\": result\n                })\n\n            # Generate final response\n            tool_messages = messages + [assistant_message.model_dump()]\n            for i, tool_call in enumerate(assistant_message.tool_calls):\n                tool_messages.append({\n                    \"role\": \"tool\",\n                    \"tool_call_id\": tool_call.id,\n                    \"content\": json.dumps(tool_results[i][\"result\"])\n                })\n\n            # ─────────────────────────────────────────────────────────────────\n            # YOUR CODE: Wrap response synthesis in a span\n            # ─────────────────────────────────────────────────────────────────\n            # with langfuse.start_as_current_span(\n            #     name=\"response-synthesis\",\n            #     input={\"tools_used\": tools_called}\n            # ) as synth_span:\n            #     final_response = self.client.chat.completions.create(...)\n            #     synth_span.update(output=response_text)\n\n            # For now, just make the call without span (you'll fix this)\n            final_response = self.client.chat.completions.create(\n                model=config.LLM_MODEL,\n                messages=[{\"role\": \"system\", \"content\": self._get_system_prompt()}] + tool_messages,\n                max_tokens=config.LLM_MAX_TOKENS\n            )\n            response_text = final_response.choices[0].message.content\n            # ─────────────────────────────────────────────────────────────────\n        else:\n            response_text = assistant_message.content or \"I couldn't process that request.\"\n\n        # Store in session\n        if session_id:\n            if session_id not in self.sessions:\n                self.sessions[session_id] = []\n            self.sessions[session_id].append({\n                \"user\": user_query,\n                \"assistant\": response_text,\n                \"tools\": tools_called\n            })\n\n        # ─────────────────────────────────────────────────────────────────────\n        # YOUR CODE: Update trace with final output\n        # ─────────────────────────────────────────────────────────────────────\n        # langfuse.update_current_trace(output=response_text)\n        pass  # YOUR CODE HERE\n        # ─────────────────────────────────────────────────────────────────────\n\n        return {\n            \"response\": response_text,\n            \"tools_called\": tools_called,\n            \"tool_results\": tool_results\n        }\n\n    def _execute_tool(self, tool_name: str, args: dict) -> dict:\n        \"\"\"Execute a tool and return results.\"\"\"\n        try:\n            if tool_name == \"search_docs\":\n                result = self.vector_db.search(args.get(\"query\", \"\"))\n                return {\"success\": True, \"data\": result}\n            elif tool_name == \"find_owner\":\n                result = self.team_db.find_owner(args.get(\"service_name\", \"\"))\n                return {\"success\": True, \"data\": result}\n            elif tool_name == \"check_status\":\n                result = self.status_api.check_status(args.get(\"service_name\", \"\"))\n                return {\"success\": True, \"data\": result}\n            else:\n                return {\"success\": False, \"error\": f\"Unknown tool: {tool_name}\"}\n        except Exception as e:\n            return {\"success\": False, \"error\": str(e)}\n\n\n# Test the class compiles\nprint(\"DevHubWithLangfuse class defined\")\nprint(\"Now implement the YOUR CODE sections!\")",
   "id": "cell-032"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SOLUTION: Task 2 - DevHubWithLangfuse with Full Instrumentation\n# =============================================================================\n# Expand this cell if you need help.\n\nfrom langfuse import observe, get_client\nfrom openai import OpenAI\nimport json\n\nclass DevHubWithLangfuseSolution:\n    \"\"\"DevHub with complete Langfuse instrumentation.\"\"\"\n\n    def __init__(self, vector_db: VectorDB, team_db: TeamDB, status_api: StatusAPI):\n        self.vector_db = vector_db\n        self.team_db = team_db\n        self.status_api = status_api\n        self.client = OpenAI()\n        self.sessions: dict[str, list] = {}\n\n        self.tools = [\n            {\"type\": \"function\", \"function\": {\"name\": \"search_docs\", \"description\": \"Search documentation\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\"}}, \"required\": [\"query\"]}}},\n            {\"type\": \"function\", \"function\": {\"name\": \"find_owner\", \"description\": \"Find service owner\", \"parameters\": {\"type\": \"object\", \"properties\": {\"service_name\": {\"type\": \"string\"}}, \"required\": [\"service_name\"]}}},\n            {\"type\": \"function\", \"function\": {\"name\": \"check_status\", \"description\": \"Check service status\", \"parameters\": {\"type\": \"object\", \"properties\": {\"service_name\": {\"type\": \"string\"}}, \"required\": [\"service_name\"]}}}\n        ]\n\n    def _get_system_prompt(self) -> str:\n        return \"You are DevHub, an AI assistant. Use search_docs for documentation, find_owner for service owners, check_status for service health.\"\n\n    def _build_messages(self, user_query: str, session_id: str = None) -> list:\n        messages = []\n        if session_id and session_id in self.sessions:\n            for turn in self.sessions[session_id][-3:]:\n                messages.append({\"role\": \"user\", \"content\": turn[\"user\"]})\n                messages.append({\"role\": \"assistant\", \"content\": turn[\"assistant\"]})\n        messages.append({\"role\": \"user\", \"content\": user_query})\n        return messages\n\n    @observe()  # SOLUTION: Add decorator\n    def query(self, user_query: str, session_id: str = None) -> dict:\n        # SOLUTION: Get client and update trace\n        langfuse = get_client()\n        langfuse.update_current_trace(\n            session_id=session_id or LAB_SESSION_ID,\n            user_id=STUDENT_NAME,\n            input=user_query,\n            metadata={\"devhub_version\": \"v4-langfuse\", \"has_history\": session_id in self.sessions if session_id else False}\n        )\n\n        messages = self._build_messages(user_query, session_id)\n\n        # SOLUTION: Tool planning span\n        with langfuse.start_as_current_span(name=\"tool-planning\", input={\"query\": user_query, \"history_length\": len(messages) - 1}) as planning_span:\n            response = self.client.chat.completions.create(\n                model=config.LLM_MODEL,\n                messages=[{\"role\": \"system\", \"content\": self._get_system_prompt()}] + messages,\n                tools=self.tools, tool_choice=\"auto\", max_tokens=config.LLM_MAX_TOKENS, temperature=config.LLM_TEMPERATURE\n            )\n            assistant_message = response.choices[0].message\n            tools_to_call = [{\"name\": tc.function.name, \"args\": json.loads(tc.function.arguments)} for tc in (assistant_message.tool_calls or [])]\n            planning_span.update(output={\"tools_selected\": [t[\"name\"] for t in tools_to_call]})\n\n        tools_called = []\n        tool_results = []\n\n        if assistant_message.tool_calls:\n            for tool_call in assistant_message.tool_calls:\n                tool_name = tool_call.function.name\n                tool_args = json.loads(tool_call.function.arguments)\n\n                # SOLUTION: Tool execution span\n                with langfuse.start_as_current_span(name=f\"tool.{tool_name}\", input=tool_args) as tool_span:\n                    result = self._execute_tool(tool_name, tool_args)\n                    tool_span.update(output=result)\n\n                tools_called.append(tool_name)\n                tool_results.append({\"tool\": tool_name, \"args\": tool_args, \"result\": result})\n\n            tool_messages = messages + [assistant_message.model_dump()]\n            for i, tool_call in enumerate(assistant_message.tool_calls):\n                tool_messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(tool_results[i][\"result\"])})\n\n            # SOLUTION: Response synthesis span\n            with langfuse.start_as_current_span(name=\"response-synthesis\", input={\"tools_used\": tools_called}) as synth_span:\n                final_response = self.client.chat.completions.create(\n                    model=config.LLM_MODEL,\n                    messages=[{\"role\": \"system\", \"content\": self._get_system_prompt()}] + tool_messages,\n                    max_tokens=config.LLM_MAX_TOKENS\n                )\n                response_text = final_response.choices[0].message.content\n                synth_span.update(output=response_text)\n        else:\n            response_text = assistant_message.content or \"I couldn't process that request.\"\n\n        if session_id:\n            if session_id not in self.sessions:\n                self.sessions[session_id] = []\n            self.sessions[session_id].append({\"user\": user_query, \"assistant\": response_text, \"tools\": tools_called})\n\n        # SOLUTION: Update trace with output\n        langfuse.update_current_trace(output=response_text)\n\n        return {\"response\": response_text, \"tools_called\": tools_called, \"tool_results\": tool_results}\n\n    def _execute_tool(self, tool_name: str, args: dict) -> dict:\n        try:\n            if tool_name == \"search_docs\": return {\"success\": True, \"data\": self.vector_db.search(args.get(\"query\", \"\"))}\n            elif tool_name == \"find_owner\": return {\"success\": True, \"data\": self.team_db.find_owner(args.get(\"service_name\", \"\"))}\n            elif tool_name == \"check_status\": return {\"success\": True, \"data\": self.status_api.check_status(args.get(\"service_name\", \"\"))}\n            else: return {\"success\": False, \"error\": f\"Unknown tool: {tool_name}\"}\n        except Exception as e: return {\"success\": False, \"error\": str(e)}\n\nprint(\"Solution: DevHubWithLangfuseSolution defined\")",
   "id": "cell-033"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TEST: Verify Your Langfuse Instrumentation\n# =============================================================================\n\n# Use your implementation or the solution\n# devhub_traced = DevHubWithLangfuse(vector_db, team_db, status_api)\ndevhub_traced = DevHubWithLangfuseSolution(vector_db, team_db, status_api)\n\n# Run a test query\ntest_result = devhub_traced.query(\"How do I authenticate with the Payments API?\")\n\nprint(f\"Response: {test_result['response'][:200]}...\")\nprint(f\"Tools called: {test_result['tools_called']}\")\nprint()\nprint(f\"View your trace at: {LANGFUSE_HOST}\")\nprint(f\"Filter by session: {LAB_SESSION_ID}\")\n\n# Flush to ensure trace is sent\nlangfuse = get_client()\nlangfuse.flush()",
   "id": "cell-034"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Test Multi-Turn: Reproduce the Bug with Visibility\n\nNow let's reproduce the \"wrong tool\" bug - but this time we can SEE why it happens!\n\n![Multi-Turn Session](https://raw.githubusercontent.com/axel-sirota/salesforce-ai-workshops/main/exercises/session_04/charts/04_multi_turn_session.svg)",
   "id": "cell-035"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TEST: Multi-Turn Bug Reproduction with Tracing\n# =============================================================================\n\n# Create a new session for this test\ndebug_session = f\"debug-session-{uuid.uuid4().hex[:6]}\"\n\nprint(\"=\" * 60)\nprint(\"TURN 1: Cancellation Request\")\nprint(\"=\" * 60)\n\nturn1 = devhub_traced.query(\n    \"I need to cancel my subscription. Who can help?\",\n    session_id=debug_session\n)\nprint(f\"Query: 'I need to cancel my subscription. Who can help?'\")\nprint(f\"Tools called: {turn1['tools_called']}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 2: Status Check (Watch for context bleed!)\")\nprint(\"=\" * 60)\n\nturn2 = devhub_traced.query(\n    \"Is the payments API working?\",\n    session_id=debug_session\n)\nprint(f\"Query: 'Is the payments API working?'\")\nprint(f\"Tools called: {turn2['tools_called']}\")\n\n# Flush traces\nlangfuse.flush()\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"VIEW YOUR TRACES\")\nprint(\"=\" * 60)\nprint(f\"Open Langfuse: {LANGFUSE_HOST}\")\nprint(f\"Filter by session_id: {debug_session}\")\nprint()\nprint(\"Look for:\")\nprint(\"1. Turn 1 trace: Should show find_owner called\")\nprint(\"2. Turn 2 trace: Check the 'tool-planning' span\")\nprint(\"3. In Turn 2's tool-planning input, look at history_length\")\nprint(\"4. The context from Turn 1 ('cancel') may have influenced Turn 2!\")",
   "id": "cell-036"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Lab 1 Complete!\n\nYou've successfully added Langfuse instrumentation to DevHub.\n\n**What you built:**\n- @observe() decorator for automatic tracing\n- Trace metadata (session_id, user_id)\n- Nested spans for tool-planning, tool execution, response-synthesis\n- Full visibility into LLM reasoning\n\n**What you can now see in Langfuse:**\n- Complete conversation history\n- Which tools were selected and why\n- Tool execution results\n- Response synthesis process\n\n**Next:** Demo of the trace replay workflow, then Lab 2 where you'll debug 4 failure scenarios.",
   "id": "cell-037"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Demo: Trace Replay Debugging Workflow\n\n## From Bug Report to Root Cause in 30 Seconds\n\n**Duration:** ~15 minutes (instructor-led)\n\nImagine you get a Slack message: *\"The AI assistant is broken for user X.\"*\n\nBefore Langfuse, your options were:\n1. Ask the user to repeat what they did\n2. Hope you can reproduce it\n3. Add more logging and wait for it to happen again\n4. Shrug and say \"LLMs are unpredictable\"\n\n**After Langfuse, your workflow is:**\n1. Filter traces by user/session ID\n2. Click on the failing request\n3. Walk through the trace step-by-step\n4. See exactly where the reasoning went wrong\n\nThis demo shows the complete debugging workflow we'll use for the rest of the session. Watch how quickly we can go from \"something's wrong\" to \"here's the root cause.\"",
   "id": "cell-038"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## The Debug Workflow\n\n**Step 1: Find the failing trace**\n- Filter by session_id, user_id, or time range\n- Look for traces with errors or unexpected outputs\n\n**Step 2: Examine the trace structure**\n- Check tool-planning span: What tools were selected?\n- Check tool execution spans: What data was returned?\n- Check response-synthesis span: What was generated?\n\n**Step 3: Identify the layer**\n- Wrong tool? → Prompt Layer (check history)\n- No/bad data? → Retrieval Layer (check results)\n- Made-up facts? → Generation Layer (compare to context)\n- Invalid params? → Validation Layer (check args)\n\n**Step 4: Fix and verify**\n- Make the fix\n- Run the same query\n- Compare traces",
   "id": "cell-039"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DEMO: Instructor walks through finding context bleed in Langfuse\n# =============================================================================\n# This code recreates the bug so instructor can demonstrate trace analysis.\n\ndemo_session = f\"demo-context-bleed-{uuid.uuid4().hex[:6]}\"\n\n# Turn 1: Sets up the \"cancel\" context\nturn1 = devhub_traced.query(\n    \"I need to cancel my billing subscription immediately!\",\n    session_id=demo_session\n)\nprint(f\"Turn 1 tools: {turn1['tools_called']}\")\n\n# Turn 2: Should check status, but might be influenced by Turn 1\nturn2 = devhub_traced.query(\n    \"What's the current status of the payments API?\",\n    session_id=demo_session\n)\nprint(f\"Turn 2 tools: {turn2['tools_called']}\")\n\nlangfuse.flush()\n\nprint(f\"\\nDemo session: {demo_session}\")\nprint(f\"Open Langfuse and filter by this session to see both traces.\")\nprint(\"\\nIn the Turn 2 trace, look at the 'tool-planning' span input.\")\nprint(\"You'll see history_length > 0, meaning Turn 1's context was included!\")",
   "id": "cell-040"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## What to Look for in Langfuse\n\n### In the Turn 2 Trace:\n\n**1. tool-planning span INPUT:**\n```json\n{\n  \"query\": \"What's the current status of the payments API?\",\n  \"history_length\": 2  // <-- This means 2 previous messages were included!\n}\n```\n\n**2. The conversation history included \"cancel\" from Turn 1**\n\n**3. tool-planning span OUTPUT:**\n```json\n{\n  \"tools_selected\": [\"find_owner\"],  // <-- Wrong! Should be check_status\n  \"tool_calls\": [...]\n}\n```\n\n### Root Cause Identified in 30 Seconds:\nThe model saw \"cancel\" in history and associated it with owner lookup context.\n\n### Fix Options:\n1. Clear session between unrelated queries\n2. Add instruction: \"Consider only the current query, not history, for tool selection\"\n3. Reduce history window from 3 turns to 1",
   "id": "cell-041"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Demo Complete!\n\n**Key takeaways:**\n\n1. **Find** → Filter traces by session/user/time\n2. **Examine** → Check span inputs and outputs\n3. **Identify** → Use 5-Layer Framework to categorize\n4. **Fix** → Address root cause, not symptoms\n\n**Your turn:** In Lab 2, you'll debug 4 different failure scenarios using this workflow.",
   "id": "cell-042"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Lab 2: Debug 4 Failure Scenarios\n\n## Practice Makes Perfect: Real Bugs, Real Fixes\n\n**Duration:** ~40 minutes\n\nTheory is nice. Debugging real failures is better.\n\nIn this lab, you'll encounter four bugs that actually happen in production LLM systems. Each one maps to a different layer of the 5-Layer Framework:\n\n| # | Scenario | Layer | What Goes Wrong |\n|---|----------|-------|-----------------|\n| 1 | **Context Bleed** | Prompt | Previous conversation leaks into current request |\n| 2 | **Retrieval Miss** | Retrieval | User asks about something not in the docs |\n| 3 | **Hallucination** | Generation | Model confidently invents facts |\n| 4 | **Bad Parameters** | Validation | Right tool, wrong arguments |\n\n**For each scenario, you will:**\n1. **Trigger** the bug intentionally\n2. **Find** the trace in Langfuse\n3. **Diagnose** using the 5-Layer Framework\n4. **Fix** (or detect) the issue with code\n\nThis is the core skill of LLM debugging: seeing the failure, understanding the layer, applying the fix.",
   "id": "cell-043"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Scenario 1: Context Bleed (Prompt Layer)\n\n![Context Bleed](https://raw.githubusercontent.com/axel-sirota/salesforce-ai-workshops/main/exercises/session_04/charts/05_context_bleed_scenario.svg)\n\n**The Bug:** Previous conversation context causes wrong tool selection.\n\n**Layer:** Prompt Layer\n\n**Your tasks:**\n1. Run the scenario code\n2. Find the trace and identify the context bleed\n3. Write code to detect when history might be causing issues",
   "id": "cell-044"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SCENARIO 1: Context Bleed\n# =============================================================================\n# Run this to create a context bleed situation, then debug it.\n\nscenario1_session = f\"scenario1-{uuid.uuid4().hex[:6]}\"\n\nprint(\"=\" * 60)\nprint(\"SCENARIO 1: Context Bleed\")\nprint(\"=\" * 60)\n\n# Turn 1: Cancellation context\ns1_turn1 = devhub_traced.query(\n    \"I need to cancel my order and get a refund. Who handles that?\",\n    session_id=scenario1_session\n)\nprint(f\"Turn 1: 'Cancel order, who handles refund?'\")\nprint(f\"  Tools: {s1_turn1['tools_called']}\")\n\n# Turn 2: Status query (should use check_status, not find_owner)\ns1_turn2 = devhub_traced.query(\n    \"Is the staging environment working right now?\",\n    session_id=scenario1_session\n)\nprint(f\"\\nTurn 2: 'Is staging working?'\")\nprint(f\"  Tools: {s1_turn2['tools_called']}\")\nprint(f\"  Expected: ['check_status']\")\nprint(f\"  Bug if: 'find_owner' was called instead\")\n\nlangfuse.flush()\nprint(f\"\\nSession ID: {scenario1_session}\")\nprint(\"Open Langfuse and examine the Turn 2 trace.\")",
   "id": "cell-045"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TASK 3: Write a Context Bleed Detector\n# =============================================================================\n# Write code that analyzes a trace and detects potential context bleed.\n#\n# TIME: ~8 minutes\n# =============================================================================\n\ndef detect_context_bleed(query: str, tools_called: list, history_length: int) -> dict:\n    \"\"\"\n    Detect if context bleed might have occurred.\n\n    Args:\n        query: The user's query\n        tools_called: List of tools that were called\n        history_length: Number of previous turns in context\n\n    Returns:\n        dict with 'likely_bleed' (bool) and 'reason' (str)\n    \"\"\"\n    # ─────────────────────────────────────────────────────────────────────────\n    # YOUR CODE HERE\n    # ─────────────────────────────────────────────────────────────────────────\n\n    # Hint: Check if the query suggests a different tool than what was called\n    # For example:\n    # - Query contains \"status\", \"working\", \"healthy\" → expect check_status\n    # - Query contains \"who owns\", \"contact\", \"help with\" → expect find_owner\n    # - Query contains \"how to\", \"documentation\", \"guide\" → expect search_docs\n\n    # If history_length > 0 AND the expected tool doesn't match called tool,\n    # that's a potential context bleed.\n\n    likely_bleed = False  # YOUR CODE: Set this based on analysis\n    reason = \"\"  # YOUR CODE: Explain why you think there's bleed (or not)\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # END YOUR CODE\n    # ─────────────────────────────────────────────────────────────────────────\n\n    return {\n        \"likely_bleed\": likely_bleed,\n        \"reason\": reason\n    }\n\n\n# Test your detector\ntest_result = detect_context_bleed(\n    query=\"Is the staging environment working?\",\n    tools_called=[\"find_owner\"],\n    history_length=2\n)\nprint(f\"Bleed detected: {test_result['likely_bleed']}\")\nprint(f\"Reason: {test_result['reason']}\")",
   "id": "cell-046"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SOLUTION: Task 3 - Context Bleed Detector\n# =============================================================================\n\ndef detect_context_bleed_solution(query: str, tools_called: list, history_length: int) -> dict:\n    \"\"\"Detect potential context bleed.\"\"\"\n\n    query_lower = query.lower()\n\n    # Determine expected tool based on query keywords\n    expected_tool = None\n\n    # Status-related keywords\n    status_keywords = [\"status\", \"working\", \"healthy\", \"up\", \"down\", \"degraded\", \"running\"]\n    if any(kw in query_lower for kw in status_keywords):\n        expected_tool = \"check_status\"\n\n    # Owner-related keywords\n    owner_keywords = [\"who owns\", \"who can help\", \"contact\", \"responsible\", \"team for\", \"cancel\", \"escalate\"]\n    if any(kw in query_lower for kw in owner_keywords):\n        expected_tool = \"find_owner\"\n\n    # Doc-related keywords\n    doc_keywords = [\"how to\", \"how do\", \"documentation\", \"guide\", \"tutorial\", \"example\", \"authenticate\"]\n    if any(kw in query_lower for kw in doc_keywords):\n        expected_tool = \"search_docs\"\n\n    # Check for bleed\n    if expected_tool and history_length > 0:\n        if expected_tool not in tools_called:\n            return {\n                \"likely_bleed\": True,\n                \"reason\": f\"Query suggests '{expected_tool}' but got {tools_called}. History length {history_length} may have influenced tool selection.\"\n            }\n\n    return {\n        \"likely_bleed\": False,\n        \"reason\": f\"Tool selection appears appropriate for query. Expected: {expected_tool}, Got: {tools_called}\"\n    }\n\n\n# Test solution\nresult = detect_context_bleed_solution(\n    query=\"Is the staging environment working?\",\n    tools_called=[\"find_owner\"],\n    history_length=2\n)\nprint(f\"Solution - Bleed detected: {result['likely_bleed']}\")\nprint(f\"Solution - Reason: {result['reason']}\")",
   "id": "cell-047"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Scenario 2: Retrieval Failure (Retrieval Layer)\n\n**The Bug:** User asks about a topic with no matching documentation.\n\n**Layer:** Retrieval Layer\n\n**Your tasks:**\n1. Run a query about something NOT in our docs\n2. Examine the retrieval results in Langfuse\n3. Write code to detect low-quality retrieval",
   "id": "cell-048"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SCENARIO 2: Retrieval Failure\n# =============================================================================\n# Query about something not in our documentation.\n\nscenario2_session = f\"scenario2-{uuid.uuid4().hex[:6]}\"\n\nprint(\"=\" * 60)\nprint(\"SCENARIO 2: Retrieval Failure\")\nprint(\"=\" * 60)\n\n# Query about Kubernetes (not in our docs!)\ns2_result = devhub_traced.query(\n    \"How do I deploy a Kubernetes pod with our auth service?\",\n    session_id=scenario2_session\n)\n\nprint(f\"Query: 'How do I deploy a Kubernetes pod with our auth service?'\")\nprint(f\"Tools called: {s2_result['tools_called']}\")\nprint(f\"\\nResponse preview: {s2_result['response'][:300]}...\")\n\nlangfuse.flush()\nprint(f\"\\nSession ID: {scenario2_session}\")\nprint(\"Check the 'tool.search_docs' span - look at the retrieval results.\")\nprint(\"Are any documents actually relevant to Kubernetes?\")\nprint(\"\\n>>> View traces: Login to Langfuse with students@salesforce.com / SalesforceWorkshop2026!\")",
   "id": "cell-049"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TASK 4: Write a Retrieval Quality Checker\n# =============================================================================\n# Check if retrieval results are actually relevant to the query.\n#\n# TIME: ~8 minutes\n# =============================================================================\n\ndef check_retrieval_quality(query: str, retrieved_docs: list, distances: list) -> dict:\n    \"\"\"\n    Check if retrieved documents are relevant to the query.\n\n    Args:\n        query: The user's search query\n        retrieved_docs: List of document contents\n        distances: List of similarity distances (lower = better)\n\n    Returns:\n        dict with 'quality' (str: good/fair/poor) and 'issues' (list)\n    \"\"\"\n    # ─────────────────────────────────────────────────────────────────────────\n    # YOUR CODE HERE\n    # ─────────────────────────────────────────────────────────────────────────\n\n    # Hint: Check these things:\n    # 1. Are there any results at all?\n    # 2. Are the distances low enough? (< 0.5 is typically good)\n    # 3. Do the documents contain keywords from the query?\n\n    quality = \"unknown\"  # YOUR CODE: Set to \"good\", \"fair\", or \"poor\"\n    issues = []  # YOUR CODE: Add strings describing any issues found\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # END YOUR CODE\n    # ─────────────────────────────────────────────────────────────────────────\n\n    return {\n        \"quality\": quality,\n        \"issues\": issues\n    }\n\n\n# Test with scenario 2 data (if available from tool results)\nif s2_result.get('tool_results'):\n    for tr in s2_result['tool_results']:\n        if tr['tool'] == 'search_docs' and tr['result'].get('success'):\n            data = tr['result']['data']\n            check = check_retrieval_quality(\n                query=\"How do I deploy a Kubernetes pod\",\n                retrieved_docs=data.get('documents', []),\n                distances=data.get('distances', [])\n            )\n            print(f\"Retrieval quality: {check['quality']}\")\n            print(f\"Issues: {check['issues']}\")",
   "id": "cell-050"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SOLUTION: Task 4 - Retrieval Quality Checker\n# =============================================================================\n\ndef check_retrieval_quality_solution(query: str, retrieved_docs: list, distances: list) -> dict:\n    \"\"\"Check retrieval quality.\"\"\"\n\n    issues = []\n    query_words = set(query.lower().split())\n\n    # Check 1: Any results?\n    if not retrieved_docs:\n        return {\"quality\": \"poor\", \"issues\": [\"No documents retrieved\"]}\n\n    # Check 2: Distance scores\n    if distances:\n        avg_distance = sum(distances) / len(distances)\n        if avg_distance > 0.7:\n            issues.append(f\"High average distance: {avg_distance:.2f} (threshold: 0.7)\")\n        if distances[0] > 0.5:\n            issues.append(f\"Best match distance {distances[0]:.2f} > 0.5 threshold\")\n\n    # Check 3: Keyword overlap\n    total_overlap = 0\n    for doc in retrieved_docs:\n        doc_words = set(doc.lower().split())\n        overlap = len(query_words & doc_words)\n        total_overlap += overlap\n\n    if total_overlap < len(query_words):\n        issues.append(f\"Low keyword overlap: {total_overlap} matches for {len(query_words)} query words\")\n\n    # Determine quality\n    if len(issues) == 0:\n        quality = \"good\"\n    elif len(issues) == 1:\n        quality = \"fair\"\n    else:\n        quality = \"poor\"\n\n    return {\"quality\": quality, \"issues\": issues}\n\n\n# Test solution\nprint(\"Testing retrieval quality checker...\")\ntest_check = check_retrieval_quality_solution(\n    query=\"Kubernetes deployment pod auth\",\n    retrieved_docs=[\"OAuth authentication with client credentials...\", \"Error handling standards...\"],\n    distances=[0.8, 0.9]\n)\nprint(f\"Quality: {test_check['quality']}\")\nprint(f\"Issues: {test_check['issues']}\")",
   "id": "cell-051"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Scenario 3: Hallucination (Generation Layer)\n\n**The Bug:** Model invents details not present in retrieved documents.\n\n**Layer:** Generation Layer\n\n**Your tasks:**\n1. Run a query where the model might hallucinate\n2. Compare the response to the retrieved context\n3. Write code to detect potential hallucinations",
   "id": "cell-052"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SCENARIO 3: Hallucination Detection\n# =============================================================================\n# Ask about something where the model might make up details.\n\nscenario3_session = f\"scenario3-{uuid.uuid4().hex[:6]}\"\n\nprint(\"=\" * 60)\nprint(\"SCENARIO 3: Hallucination\")\nprint(\"=\" * 60)\n\n# Query that might trigger hallucination\ns3_result = devhub_traced.query(\n    \"What's the exact rate limit for the Premium Plus tier on the Payments API?\",\n    session_id=scenario3_session\n)\n\nprint(f\"Query: 'What's the exact rate limit for the Premium Plus tier?'\")\nprint(f\"Tools called: {s3_result['tools_called']}\")\nprint(f\"\\nResponse:\\n{s3_result['response']}\")\n\nlangfuse.flush()\nprint(f\"\\nSession ID: {scenario3_session}\")\nprint(\"\\nCheck: Does our documentation mention 'Premium Plus tier'?\")\nprint(\"If the model gave a specific number, did it come from the docs or was it invented?\")\nprint(\"\\n>>> View traces: Login to Langfuse with students@salesforce.com / SalesforceWorkshop2026!\")",
   "id": "cell-053"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TASK 5: Write a Simple Hallucination Detector\n# =============================================================================\n# Check if the response contains claims not in the source documents.\n#\n# TIME: ~10 minutes\n# =============================================================================\nimport re\n\ndef detect_hallucination(response: str, source_docs: list) -> dict:\n    \"\"\"\n    Detect if the response contains information not in source documents.\n\n    Args:\n        response: The model's response\n        source_docs: List of source document contents\n\n    Returns:\n        dict with 'likely_hallucination' (bool), 'suspicious_claims' (list)\n    \"\"\"\n    # ─────────────────────────────────────────────────────────────────────────\n    # YOUR CODE HERE\n    # ─────────────────────────────────────────────────────────────────────────\n\n    # Hint: Look for specific patterns that indicate potential hallucination:\n    # 1. Specific numbers (rates, percentages, limits) not in sources\n    # 2. Product names or tier names not mentioned in sources\n    # 3. Dates or version numbers not in sources\n\n    # Combine all source docs into one text for searching\n    # all_sources = \" \".join(source_docs).lower()\n\n    # Extract specific claims from response (numbers, proper nouns, etc.)\n    # Check if they appear in sources\n\n    likely_hallucination = False  # YOUR CODE\n    suspicious_claims = []  # YOUR CODE: List of claims that seem made up\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # END YOUR CODE\n    # ─────────────────────────────────────────────────────────────────────────\n\n    return {\n        \"likely_hallucination\": likely_hallucination,\n        \"suspicious_claims\": suspicious_claims\n    }\n\n\n# Test with scenario 3\nif s3_result.get('tool_results'):\n    for tr in s3_result['tool_results']:\n        if tr['tool'] == 'search_docs' and tr['result'].get('success'):\n            source_docs = tr['result']['data'].get('documents', [])\n            result = detect_hallucination(s3_result['response'], source_docs)\n            print(f\"Likely hallucination: {result['likely_hallucination']}\")\n            print(f\"Suspicious claims: {result['suspicious_claims']}\")",
   "id": "cell-054"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SOLUTION: Task 5 - Hallucination Detector\n# =============================================================================\nimport re\n\ndef detect_hallucination_solution(response: str, source_docs: list) -> dict:\n    \"\"\"Detect potential hallucinations.\"\"\"\n\n    suspicious_claims = []\n    all_sources = \" \".join(source_docs).lower()\n\n    # Extract numbers from response\n    numbers_in_response = re.findall(r'\\b\\d+(?:,\\d{3})*(?:\\.\\d+)?\\b', response)\n\n    # Check if numbers appear in sources\n    for num in numbers_in_response:\n        if num not in all_sources:\n            suspicious_claims.append(f\"Number '{num}' not found in source documents\")\n\n    # Check for tier/plan names not in sources\n    tier_patterns = [\"premium plus\", \"enterprise\", \"professional\", \"basic tier\", \"standard tier\"]\n    response_lower = response.lower()\n    for tier in tier_patterns:\n        if tier in response_lower and tier not in all_sources:\n            suspicious_claims.append(f\"Tier '{tier}' mentioned but not in sources\")\n\n    # Check for specific endpoint paths\n    endpoints = re.findall(r'/[a-z]+/v\\d+/[a-z]+', response.lower())\n    for endpoint in endpoints:\n        if endpoint not in all_sources:\n            suspicious_claims.append(f\"Endpoint '{endpoint}' not found in sources\")\n\n    likely_hallucination = len(suspicious_claims) > 0\n\n    return {\n        \"likely_hallucination\": likely_hallucination,\n        \"suspicious_claims\": suspicious_claims\n    }\n\n\n# Test solution\ntest_response = \"The Premium Plus tier has a rate limit of 5000 requests per minute.\"\ntest_sources = [\"Default rate limits: 100 req/min for standard tier, 1000 req/min for premium.\"]\nresult = detect_hallucination_solution(test_response, test_sources)\nprint(f\"Solution - Likely hallucination: {result['likely_hallucination']}\")\nprint(f\"Solution - Suspicious claims: {result['suspicious_claims']}\")",
   "id": "cell-055"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Scenario 4: Parameter Error (Validation Layer)\n\n**The Bug:** Model calls the right tool with wrong parameters.\n\n**Layer:** Validation Layer\n\n**Your tasks:**\n1. Run a query that results in invalid parameters\n2. Check the tool call arguments in Langfuse\n3. Write code to validate tool parameters",
   "id": "cell-056"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SCENARIO 4: Parameter Error\n# =============================================================================\n# Query that might result in wrong parameters.\n\nscenario4_session = f\"scenario4-{uuid.uuid4().hex[:6]}\"\n\nprint(\"=\" * 60)\nprint(\"SCENARIO 4: Parameter Error\")\nprint(\"=\" * 60)\n\n# Query with ambiguous service name\ns4_result = devhub_traced.query(\n    \"Check the status of the payment-processing-v2 service\",\n    session_id=scenario4_session\n)\n\nprint(f\"Query: 'Check status of payment-processing-v2'\")\nprint(f\"Tools called: {s4_result['tools_called']}\")\n\n# Check what parameter was passed\nif s4_result.get('tool_results'):\n    for tr in s4_result['tool_results']:\n        if tr['tool'] == 'check_status':\n            print(f\"Parameter passed: {tr['args']}\")\n            print(f\"Result: {tr['result']}\")\n\nlangfuse.flush()\nprint(f\"\\nSession ID: {scenario4_session}\")\nprint(\"\\nCheck: Does 'payment-processing-v2' match any valid service?\")\nprint(\"Valid services: payments-api, auth-service, staging, vector-search, api-gateway\")\nprint(\"\\n>>> View traces: Login to Langfuse with students@salesforce.com / SalesforceWorkshop2026!\")",
   "id": "cell-057"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TASK 6: Write a Parameter Validator\n# =============================================================================\n# Validate that tool parameters match known valid values.\n#\n# TIME: ~8 minutes\n# =============================================================================\n\n# Known valid services (from our STATUS_DATA)\nVALID_SERVICES = [\"payments-api\", \"auth-service\", \"staging\", \"vector-search\", \"api-gateway\"]\n\ndef validate_tool_params(tool_name: str, args: dict) -> dict:\n    \"\"\"\n    Validate tool parameters against known valid values.\n\n    Args:\n        tool_name: Name of the tool called\n        args: Arguments passed to the tool\n\n    Returns:\n        dict with 'valid' (bool), 'errors' (list), 'suggestions' (list)\n    \"\"\"\n    # ─────────────────────────────────────────────────────────────────────────\n    # YOUR CODE HERE\n    # ─────────────────────────────────────────────────────────────────────────\n\n    # Hint: For check_status tool:\n    # 1. Get the service_name parameter\n    # 2. Check if it's in VALID_SERVICES\n    # 3. If not, find the closest match (fuzzy matching)\n\n    valid = True  # YOUR CODE\n    errors = []  # YOUR CODE\n    suggestions = []  # YOUR CODE: Suggest valid alternatives\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # END YOUR CODE\n    # ─────────────────────────────────────────────────────────────────────────\n\n    return {\n        \"valid\": valid,\n        \"errors\": errors,\n        \"suggestions\": suggestions\n    }\n\n\n# Test\nresult = validate_tool_params(\"check_status\", {\"service_name\": \"payment-processing-v2\"})\nprint(f\"Valid: {result['valid']}\")\nprint(f\"Errors: {result['errors']}\")\nprint(f\"Suggestions: {result['suggestions']}\")",
   "id": "cell-058"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SOLUTION: Task 6 - Parameter Validator\n# =============================================================================\n\ndef validate_tool_params_solution(tool_name: str, args: dict) -> dict:\n    \"\"\"Validate tool parameters.\"\"\"\n\n    errors = []\n    suggestions = []\n\n    if tool_name == \"check_status\":\n        service_name = args.get(\"service_name\", \"\")\n\n        # Check exact match\n        if service_name.lower() in [s.lower() for s in VALID_SERVICES]:\n            return {\"valid\": True, \"errors\": [], \"suggestions\": []}\n\n        # Check partial match\n        errors.append(f\"Unknown service: '{service_name}'\")\n\n        # Find similar services\n        service_lower = service_name.lower()\n        for valid_service in VALID_SERVICES:\n            # Check if any part matches\n            if any(part in valid_service for part in service_lower.split(\"-\")):\n                suggestions.append(valid_service)\n\n        if not suggestions:\n            suggestions = VALID_SERVICES[:3]  # Show first 3 as examples\n\n        return {\"valid\": False, \"errors\": errors, \"suggestions\": suggestions}\n\n    elif tool_name == \"find_owner\":\n        service_name = args.get(\"service_name\", \"\")\n        if not service_name:\n            return {\"valid\": False, \"errors\": [\"Missing service_name\"], \"suggestions\": []}\n        return {\"valid\": True, \"errors\": [], \"suggestions\": []}\n\n    elif tool_name == \"search_docs\":\n        query = args.get(\"query\", \"\")\n        if not query or len(query) < 3:\n            return {\"valid\": False, \"errors\": [\"Query too short\"], \"suggestions\": []}\n        return {\"valid\": True, \"errors\": [], \"suggestions\": []}\n\n    return {\"valid\": True, \"errors\": [], \"suggestions\": []}\n\n\n# Test solution\nresult = validate_tool_params_solution(\"check_status\", {\"service_name\": \"payment-processing-v2\"})\nprint(f\"Solution - Valid: {result['valid']}\")\nprint(f\"Solution - Errors: {result['errors']}\")\nprint(f\"Solution - Suggestions: {result['suggestions']}\")",
   "id": "cell-059"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Lab 2 Complete!\n\nYou've debugged 4 different LLM failure scenarios:\n\n| Scenario | Layer | What You Built |\n|----------|-------|----------------|\n| Context Bleed | Prompt | `detect_context_bleed()` function |\n| Retrieval Failure | Retrieval | `check_retrieval_quality()` function |\n| Hallucination | Generation | `detect_hallucination()` function |\n| Parameter Error | Validation | `validate_tool_params()` function |\n\n**Key skill:** Using traces to identify the layer, then writing code to detect similar issues.\n\n**Next:** Lab 3 - Convert one of these failures into a regression test.",
   "id": "cell-060"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Lab 3: Convert Failures to Regression Tests\n\n## Never Fix the Same Bug Twice\n\n**Duration:** ~25 minutes\n\n![Failure to Test Pipeline](https://raw.githubusercontent.com/axel-sirota/salesforce-ai-workshops/main/exercises/session_04/charts/06_failure_to_test_pipeline.svg)\n\nHere's a frustrating pattern in LLM development:\n\n1. User reports a bug\n2. You investigate and fix it\n3. Two weeks later, same bug happens again\n4. *\"I thought we fixed this!\"*\n\nThe problem: LLM behavior can regress without any code changes. A prompt tweak here, a retrieval update there—suddenly old bugs resurface.\n\n**The solution:** Convert every production failure into an automated test.\n\n**The Failure-to-Test Pipeline:**\n\n| Step | Action | Tool |\n|------|--------|------|\n| 1 | Find the failing trace | Langfuse |\n| 2 | Identify the layer | 5-Layer Framework |\n| 3 | Export the test case | query + response + context |\n| 4 | Measure with metrics | DeepEval FaithfulnessMetric |\n| 5 | Add to CI/CD | pytest regression suite |\n\nBy the end of this lab, the hallucination bug from Scenario 3 will have an automated test that runs on every deploy.",
   "id": "cell-061"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## DeepEval FaithfulnessMetric\n\n**What it does:** Checks if a response is faithful to (grounded in) the provided context.\n\n**How it works:**\n1. Extracts claims from the response\n2. Checks if each claim is supported by the context\n3. Returns a score (0-1) and pass/fail based on threshold\n\n**Pattern:**\n```python\nfrom deepeval.test_case import LLMTestCase\nfrom deepeval.metrics import FaithfulnessMetric\n\n# Create test case\ntest_case = LLMTestCase(\n    input=\"What's the rate limit?\",\n    actual_output=\"The rate limit is 100 requests per minute.\",\n    retrieval_context=[\"Rate limits: 100 req/min standard, 1000 req/min premium.\"]\n)\n\n# Run faithfulness check\nmetric = FaithfulnessMetric(threshold=0.7)\nmetric.measure(test_case)\nprint(f\"Score: {metric.score}, Passed: {metric.is_successful()}\")\n```",
   "id": "cell-062"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TASK 7: Extract Test Case from Scenario 3\n# =============================================================================\n# Create a test case from the hallucination scenario.\n#\n# TIME: ~5 minutes\n# =============================================================================\n\nfrom deepeval.test_case import LLMTestCase\nfrom deepeval.metrics import FaithfulnessMetric\n\n# We'll use the scenario 3 data\ntest_query = \"What's the exact rate limit for the Premium Plus tier on the Payments API?\"\n\n# Get the response and context from scenario 3\ntest_response = s3_result['response']\n\n# Extract retrieval context from tool results\nretrieval_context = []\nfor tr in s3_result.get('tool_results', []):\n    if tr['tool'] == 'search_docs' and tr['result'].get('success'):\n        retrieval_context = tr['result']['data'].get('documents', [])\n        break\n\nprint(\"Extracted from Scenario 3 trace:\")\nprint(f\"  Query: {test_query[:50]}...\")\nprint(f\"  Response: {test_response[:100]}...\")\nprint(f\"  Context docs: {len(retrieval_context)}\")\n\n# ─────────────────────────────────────────────────────────────────────────────\n# YOUR CODE: Create the LLMTestCase\n# ─────────────────────────────────────────────────────────────────────────────\n\n# hallucination_test_case = LLMTestCase(\n#     input=...,\n#     actual_output=...,\n#     retrieval_context=...\n# )\n\nhallucination_test_case = None  # YOUR CODE HERE\n\n# ─────────────────────────────────────────────────────────────────────────────\n# END YOUR CODE\n# ─────────────────────────────────────────────────────────────────────────────\n\nif hallucination_test_case:\n    print(\"\\nTest case created successfully!\")",
   "id": "cell-063"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SOLUTION: Task 7 - Create Test Case\n# =============================================================================\n\nhallucination_test_case = LLMTestCase(\n    input=test_query,\n    actual_output=test_response,\n    retrieval_context=retrieval_context\n)\n\nprint(\"Solution - Test case created:\")\nprint(f\"  Input: {hallucination_test_case.input[:50]}...\")\nprint(f\"  Output: {hallucination_test_case.actual_output[:50]}...\")\nprint(f\"  Context items: {len(hallucination_test_case.retrieval_context)}\")",
   "id": "cell-064"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TASK 8: Run FaithfulnessMetric on the Test Case\n# =============================================================================\n# Check if the response is faithful to the retrieval context.\n#\n# TIME: ~5 minutes\n# =============================================================================\n\n# ─────────────────────────────────────────────────────────────────────────────\n# YOUR CODE: Create and run the FaithfulnessMetric\n# ─────────────────────────────────────────────────────────────────────────────\n\n# Hint:\n# 1. Create FaithfulnessMetric with threshold=0.7\n# 2. Call metric.measure(test_case)\n# 3. Check metric.score and metric.is_successful()\n\n# metric = FaithfulnessMetric(threshold=0.7, include_reason=True)\n# metric.measure(hallucination_test_case)\n\n# print(f\"Score: {metric.score}\")\n# print(f\"Passed: {metric.is_successful()}\")\n# print(f\"Reason: {metric.reason}\")\n\nprint(\"YOUR CODE: Run the FaithfulnessMetric\")\n\n# ─────────────────────────────────────────────────────────────────────────────\n# END YOUR CODE\n# ─────────────────────────────────────────────────────────────────────────────",
   "id": "cell-065"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SOLUTION: Task 8 - Run FaithfulnessMetric\n# =============================================================================\n\nprint(\"Running FaithfulnessMetric (this may take a few seconds)...\")\n\nfaithfulness_metric = FaithfulnessMetric(threshold=0.7, include_reason=True)\n\ntry:\n    faithfulness_metric.measure(hallucination_test_case)\n\n    print(f\"\\nFaithfulness Score: {faithfulness_metric.score:.2f}\")\n    print(f\"Passed (>= 0.7): {faithfulness_metric.is_successful()}\")\n    print(f\"\\nReason: {faithfulness_metric.reason}\")\n\n    if not faithfulness_metric.is_successful():\n        print(\"\\n HALLUCINATION DETECTED!\")\n        print(\"The response contains claims not supported by the retrieval context.\")\nexcept Exception as e:\n    print(f\"Error running metric: {e}\")\n    print(\"(This may happen if you don't have OpenAI credits)\")",
   "id": "cell-066"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TASK 9: Create a Reusable Regression Test Function\n# =============================================================================\n# This function can be added to your CI/CD pipeline.\n#\n# TIME: ~8 minutes\n# =============================================================================\n\ndef test_no_hallucinated_rate_limits():\n    \"\"\"\n    Regression test: DevHub should not invent rate limits.\n\n    Bug: HALL-001\n    Root cause: Model extrapolated tier names not in documentation\n    Fix: Added grounding instructions to system prompt\n\n    This test ensures the fix hasn't regressed.\n    \"\"\"\n    # ─────────────────────────────────────────────────────────────────────────\n    # YOUR CODE HERE\n    # ─────────────────────────────────────────────────────────────────────────\n\n    # 1. Run the query that caused the original bug\n    # result = devhub_traced.query(\"What's the rate limit for Premium Plus tier?\")\n\n    # 2. Extract response and retrieval context\n    # response = result['response']\n    # context = [extract from tool_results]\n\n    # 3. Create test case\n    # test_case = LLMTestCase(input=..., actual_output=..., retrieval_context=...)\n\n    # 4. Run faithfulness check\n    # metric = FaithfulnessMetric(threshold=0.7)\n    # metric.measure(test_case)\n\n    # 5. Assert the test passes\n    # assert metric.is_successful(), f\"Hallucination detected: {metric.reason}\"\n\n    print(\"YOUR CODE: Implement the regression test function\")\n    pass\n\n    # ─────────────────────────────────────────────────────────────────────────\n    # END YOUR CODE\n    # ─────────────────────────────────────────────────────────────────────────\n\n\n# Run the test\nprint(\"Testing regression test function...\")\ntest_no_hallucinated_rate_limits()",
   "id": "cell-067"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SOLUTION: Task 9 - Regression Test Function\n# =============================================================================\n\ndef test_no_hallucinated_rate_limits_solution():\n    \"\"\"\n    Regression test: DevHub should not invent rate limits.\n\n    Bug: HALL-001 (detected in Scenario 3)\n    Root cause: Model extrapolated tier names not in documentation\n    \"\"\"\n    # 1. Run the problematic query\n    result = devhub_traced.query(\n        \"What are the rate limits for different tiers?\",\n        session_id=f\"regression-{uuid.uuid4().hex[:6]}\"\n    )\n\n    # 2. Extract data\n    response = result['response']\n    context = []\n    for tr in result.get('tool_results', []):\n        if tr['tool'] == 'search_docs' and tr['result'].get('success'):\n            context = tr['result']['data'].get('documents', [])\n            break\n\n    # 3. Create test case\n    test_case = LLMTestCase(\n        input=\"What are the rate limits for different tiers?\",\n        actual_output=response,\n        retrieval_context=context\n    )\n\n    # 4. Run faithfulness check\n    metric = FaithfulnessMetric(threshold=0.7, include_reason=True)\n    metric.measure(test_case)\n\n    # 5. Report results\n    print(f\"Faithfulness score: {metric.score:.2f}\")\n    print(f\"Test passed: {metric.is_successful()}\")\n\n    if not metric.is_successful():\n        print(f\"REGRESSION DETECTED: {metric.reason}\")\n        # In CI/CD, this would be: assert metric.is_successful()\n\n    langfuse.flush()\n    return metric.is_successful()\n\n\n# Run solution\nprint(\"Running regression test solution...\")\ntry:\n    passed = test_no_hallucinated_rate_limits_solution()\n    print(f\"\\nFinal result: {'PASS' if passed else 'FAIL'}\")\nexcept Exception as e:\n    print(f\"Test error: {e}\")",
   "id": "cell-068"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Lab 3 Complete!\n\nYou've built a complete failure-to-test pipeline:\n\n**What you created:**\n1. **Test case extraction** from Langfuse traces\n2. **FaithfulnessMetric** evaluation\n3. **Regression test function** for CI/CD\n\n**The pattern:**\n```python\ndef test_regression_bug_XXX():\n    # 1. Run the query that caused the bug\n    result = devhub.query(\"...\")\n\n    # 2. Create test case with retrieval context\n    test_case = LLMTestCase(input=..., actual_output=..., retrieval_context=...)\n\n    # 3. Run appropriate metric\n    metric = FaithfulnessMetric(threshold=0.7)\n    metric.measure(test_case)\n\n    # 4. Assert\n    assert metric.is_successful(), f\"Regression: {metric.reason}\"\n```\n\n**Add to CI/CD:**\n- Run these tests on every PR\n- If they fail, the bug has returned\n- Never fix the same bug twice!",
   "id": "cell-069"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Wrap-Up: Before and After\n\n## From Black Box to Glass Box\n\n![Before After](https://raw.githubusercontent.com/axel-sirota/salesforce-ai-workshops/main/exercises/session_04/charts/07_before_after_debugging.svg)\n\nLook how far we've come in this session.\n\n**Before today:**\n- LLM bugs were mysterious and unpredictable\n- Debugging meant \"try random things and hope\"\n- No systematic way to understand failures\n- Same bugs kept happening over and over\n\n**After today:**\n- Every LLM decision is visible in Langfuse traces\n- 5-Layer Framework gives you a diagnosis path\n- Trace replay lets you debug in seconds\n- Failures become tests that prevent regressions\n\nThis is the difference between *hoping* your AI works and *knowing* it works.",
   "id": "cell-070"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Takeaways\n\n### 1. LLM Bugs Are Different\n- Traditional debugging shows WHAT happened\n- LLM debugging shows WHY the model decided\n- Different tools for different bug types\n\n### 2. The 5-Layer Framework\n| Layer | Debug Focus |\n|-------|-------------|\n| Prompt | History, tool descriptions, system prompt |\n| Retrieval | Similarity scores, document relevance |\n| Generation | Compare output to context |\n| Validation | Parameter values, schema compliance |\n| Latency | Span timings, token counts |\n\n### 3. The Debug Workflow\n1. **Find** the trace\n2. **Identify** the layer\n3. **Analyze** inputs and outputs\n4. **Fix** the root cause\n5. **Test** to prevent regression\n\n### 4. Tools You Learned\n- **Langfuse:** LLM observability (traces, spans, generations)\n- **DeepEval:** Evaluation metrics (FaithfulnessMetric)\n- **Your detectors:** Context bleed, retrieval quality, hallucination, parameter validation",
   "id": "cell-071"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Take-Home Challenge\n\n**Challenge:** Build a comprehensive debug toolkit for DevHub.\n\n**Requirements:**\n\n1. **Create a DebugToolkit class** that combines all 4 detectors:\n   ```python\n   class DebugToolkit:\n       def analyze_trace(self, trace_data: dict) -> dict:\n           # Run all detectors\n           # Return comprehensive analysis\n   ```\n\n2. **Add automatic layer identification:**\n   - Based on symptoms, suggest which layer to investigate\n\n3. **Create 3 more regression tests** for other failure scenarios:\n   - Context bleed regression test\n   - Retrieval failure regression test\n   - Parameter error regression test\n\n4. **Bonus:** Create a Langfuse dashboard that shows:\n   - Traces with potential issues (filtered by your detectors)\n   - Failure rate by layer\n   - Regression test results over time",
   "id": "cell-072"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## What's Next\n\n### Session 5: Guardrails & Safety\n- Input/output validation\n- Content filtering\n- Bias detection\n- Rate limiting for AI\n\n### Session 6: Production Deployment\n- Scaling considerations\n- Cost optimization\n- Monitoring dashboards\n- Incident response\n\n### Resources\n- **Langfuse Docs:** https://langfuse.com/docs\n- **DeepEval Docs:** https://docs.confident-ai.com/\n- **OpenTelemetry + Langfuse:** https://langfuse.com/docs/integrations/opentelemetry",
   "id": "cell-073"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Questions?\n\n**Feedback:** [Workshop Feedback Form]\n\n**Support:**\n- Workshop Slack: #ai-workshop-support\n- Langfuse Discord: https://discord.gg/langfuse\n\n**Code Repository:** [GitHub Link]\n\n---\n\n**Thank you for attending Session 4!**\n\nYou now have the skills to debug LLM applications like a pro.",
   "id": "cell-074"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CLEANUP: Flush all traces\n# =============================================================================\n\nlangfuse = get_client()\nlangfuse.flush()\n\nprint(\"All traces flushed to Langfuse.\")\nprint(f\"\\nYour traces are available at: {LANGFUSE_HOST}\")\nprint(f\"Filter by user_id: {STUDENT_NAME}\")\nprint(\"\\n>>> View traces: Login to Langfuse with students@salesforce.com / SalesforceWorkshop2026!\")\nprint(\"\\nSession 4 Complete!\")",
   "id": "cell-075"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}